{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":407317,"sourceType":"datasetVersion","datasetId":181273}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/esracum/lgg-mri-segmentation?scriptVersionId=291071930\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# U-Net nedir? ","metadata":{}},{"cell_type":"markdown","source":"\nU-Net, özellikle tıbbi görüntüleme ve segmentasyon görevlerinde etkili olan bir derin öğrenme mimarisidir. 2015 yılında Olaf Ronneberger ve arkadaşları tarafından tanıtılmıştır ve temel olarak iki aşamalı bir yapıdan oluşur: encoder ve decoder.","metadata":{}},{"cell_type":"markdown","source":"# U-Net Mimarisinin Temel Özellikleri?","metadata":{}},{"cell_type":"code","source":"#     [Input Image]\n#           ↓\n#     [Encoder Path]\n#           ↓\n#     [Bottleneck]\n#           ↓\n#     [Decoder Path]\n#           ↓\n#     [Output Image]\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"U-Net Mimarisinin Temel Özellikleri:\nEnkoder (Encoder) Bölümü:\n\nKonvolüsyonel Katmanlar: Girdi görüntüsünden özellikleri çıkarmak için bir dizi konvolüsyonel katman kullanır.\nMax Pooling: Özellik haritasının boyutlarını küçültmek ve önemli özellikleri öğrenmek için kullanılır. Bu işlem, özelliklerin genel bir temsiline geçiş yapar.\nDekoder (Decoder) Bölümü:\n\nUp-sampling: Özellik haritalarını orijinal boyutlarına geri getirmek için up-sampling (büyütme) işlemi yapar.\nKonvolüsyonel Katmanlar: Up-sampling işlemi sonrasında elde edilen özellik haritalarını daha ayrıntılı hale getirir.\nSkip Connections: Enkoder bölümündeki özellik haritalarını dekoder bölümüne doğrudan aktarır. Bu, hem yüksek düzeyde hem de ayrıntılı özelliklerin kullanılmasını sağlar ve segmentasyon sonucunun daha hassas olmasına yardımcı olur.\nSonuç:\n\nSon Konvolüsyon Katmanı: Sonuç olarak, çıktı sınıf sayısına göre bir konvolüsyon katmanı eklenir. Bu katman, segmentasyon sonucunu üretir.\n","metadata":{}},{"cell_type":"markdown","source":"# U-Net Mimarisinin Avantajları?","metadata":{}},{"cell_type":"markdown","source":"Ayrıntılı Segmentasyon: Skip connections, modelin hem büyük yapıları hem de ince detayları öğrenmesine yardımcı olur, bu da ayrıntılı segmentasyon sonuçları sağlar.\nEtkili Eğitim: U-Net, özellikle sınırlı veri miktarıyla etkili bir şekilde çalışabilir, çünkü skip connections daha az veriyle modelin performansını iyileştirir.\nİyi Performans: Tıbbi görüntüleme gibi yüksek hassasiyet gerektiren görevlerde etkili bir performans sergiler.","metadata":{}},{"cell_type":"markdown","source":"# U-Net'in Kullanım Alanları","metadata":{}},{"cell_type":"markdown","source":"Tıbbi Görüntüleme: MR, CT taramaları gibi tıbbi görüntülerde organ segmentasyonu ve lezyon tespiti.\nGörüntü Segmentasyonu: Genel görüntü segmentasyonu görevlerinde kullanılır.\nGörüntü İyileştirme: Görüntülerin düzeltilmesi veya iyileştirilmesi görevlerinde de uygulanabilir.","metadata":{}},{"cell_type":"markdown","source":"# Gerekli Kütüphanelerin İmport Edilmesi","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tensorflow.keras import backend as K\n\nplt.style.use(\"ggplot\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:13.040453Z","iopub.execute_input":"2024-08-20T07:20:13.040878Z","iopub.status.idle":"2024-08-20T07:20:13.046592Z","shell.execute_reply.started":"2024-08-20T07:20:13.040842Z","shell.execute_reply":"2024-08-20T07:20:13.045646Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\nimport cv2\nfrom tqdm import tqdm_notebook, tnrange\nfrom glob import glob\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-20T07:19:45.075214Z","iopub.execute_input":"2024-08-20T07:19:45.07581Z","iopub.status.idle":"2024-08-20T07:20:10.431762Z","shell.execute_reply.started":"2024-08-20T07:19:45.075779Z","shell.execute_reply":"2024-08-20T07:20:10.430829Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Setting size parameters of images\nim_width = 256\nim_height = 256","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:10.433441Z","iopub.execute_input":"2024-08-20T07:20:10.434077Z","iopub.status.idle":"2024-08-20T07:20:10.438713Z","shell.execute_reply.started":"2024-08-20T07:20:10.434048Z","shell.execute_reply":"2024-08-20T07:20:10.437814Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_filenames_train = []\n\n# creating a list of all files containing the word 'mask'\n# in Local Machine\n# mask_files = glob('../../input/lgg-mri-segmentation/kaggle_3m/*/*_mask*')\n\n# in Kaggle\nmask_files = glob('../input/lgg-mri-segmentation/kaggle_3m/*/*_mask*')\n\nfor i in mask_files:\n    image_filenames_train.append(i.replace('_mask', ''))\n\nprint(image_filenames_train[:10])\nlen(image_filenames_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:10.44016Z","iopub.execute_input":"2024-08-20T07:20:10.440563Z","iopub.status.idle":"2024-08-20T07:20:13.037533Z","shell.execute_reply.started":"2024-08-20T07:20:10.440519Z","shell.execute_reply":"2024-08-20T07:20:13.036507Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Görüntü ve Maskeleri Görselleştirme Fonksiyonu","metadata":{}},{"cell_type":"code","source":"def plot_from_img_path(rows, columns, list_img_path, list_mask_path):\n    \"\"\" \n    Bu fonksiyon, verilen görüntü ve maske yollarından bir grid (ızgara) oluşturur ve bunları görüntüler.\n    Görüntüleri okumak ve işlemek için OpenCV kullanır, plot işlemi için matplotlib kullanılır.\n\n    Parametreler:\n    -----------\n    rows : int\n        Grid'in satır sayısı.\n\n    columns : int\n        Grid'in sütun sayısı.\n\n    list_img_path : list of str\n        Görüntü dosyalarının yolunu içeren liste.\n\n    list_mask_path : list of str\n        Maske dosyalarının yolunu içeren liste.\n    \"\"\"\n    fig = plt.figure(figsize=(12, 12))\n    for i in range(1, rows * columns + 1):\n        fig.add_subplot(rows, columns, i)\n        img_path = list_img_path[i]\n        mask_path = list_mask_path[i]\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(mask_path)\n        plt.imshow(image)\n        plt.imshow(mask, alpha=0.3)\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:13.047717Z","iopub.execute_input":"2024-08-20T07:20:13.048019Z","iopub.status.idle":"2024-08-20T07:20:13.066917Z","shell.execute_reply.started":"2024-08-20T07:20:13.047992Z","shell.execute_reply":"2024-08-20T07:20:13.066129Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dice Katsayısı Hesaplama Fonksiyonu","metadata":{}},{"cell_type":"markdown","source":"* Dice Katsayısı: Bu fonksiyon, görüntü segmentasyonunda kullanılan bir ölçüt olan Dice katsayısını hesaplar. Bu katsayı, tahmin edilen ve gerçek değerler arasındaki örtüşme miktarını gösterir.","metadata":{}},{"cell_type":"code","source":"def dice_coefficients(y_true, y_pred, smooth=100):\n    \"\"\"\n    Gerçek ve tahmin edilen değerler arasındaki Dice benzerlik katsayısını hesaplar.\n\n    Dice katsayısı, iki örnek arasındaki benzerliği ölçmek için kullanılan bir metriktir. \n    0 ile 1 arasında bir değer alır; 1, iki örneğin tamamen aynı olduğunu, 0 ise hiç örtüşmediklerini belirtir.\n\n    Parametreler:\n    -----------\n    y_true : tensor\n        Gerçek değerler (genellikle bir ikili maske).\n\n    y_pred : tensor\n        Tahmin edilen değerler (genellikle bir ikili maske).\n\n    smooth : float, optional\n        Sıfır bölmeyi önlemek için kullanılan bir düzeltme faktörü. Varsayılan değer 100'dür.\n    \n    Döndürülen:\n    --------\n    float\n        Gerçek ve tahmin edilen değerler arasındaki Dice benzerlik katsayısı.\n    \"\"\"\n    y_true_flatten = K.flatten(y_true)\n    y_pred_flatten = K.flatten(y_pred)\n\n    intersection = K.sum(y_true_flatten * y_pred_flatten)\n    union = K.sum(y_true_flatten) + K.sum(y_pred_flatten)\n    return (2 * intersection + smooth) / (union + smooth)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:13.068192Z","iopub.execute_input":"2024-08-20T07:20:13.06848Z","iopub.status.idle":"2024-08-20T07:20:13.085636Z","shell.execute_reply.started":"2024-08-20T07:20:13.068455Z","shell.execute_reply":"2024-08-20T07:20:13.084839Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dice Kayıp Fonksiyonu","metadata":{}},{"cell_type":"markdown","source":"* Dice Kaybı: Bu fonksiyon, segmentasyon modelleri için Dice kaybını hesaplar. Kayıp fonksiyonu olarak negatif Dice katsayısı kullanılır, çünkü optimizasyon algoritmaları genellikle minimize etmek için tasarlanmıştır.","metadata":{}},{"cell_type":"code","source":"def dice_coefficients_loss(y_true, y_pred, smooth=100):\n    \"\"\"\n    Görüntü segmentasyon modelleri için Dice kaybı fonksiyonu.\n\n    Dice kaybı, tahmin edilen (y_pred) ve gerçek (y_true) maskeler arasındaki örtüşmeyi ölçer.\n    Optimizasyon algoritmaları genellikle bir fonksiyonu minimize etmek için tasarlandığından,\n    Dice katsayısının negatifini alırız, böylece optimizasyon süreci bu kaybı minimize etmeye çalışır.\n\n    Parametreler:\n    -----------\n    y_true : tensor\n        Gerçek değerler (genellikle bir ikili maske).\n\n    y_pred : tensor\n        Tahmin edilen değerler (genellikle bir ikili maske).\n\n    smooth : float, optional\n        Sıfır bölmeyi önlemek için kullanılan bir düzeltme faktörü. Varsayılan değer 100'dür.\n    \n    Döndürülen:\n    --------\n    float\n        Hesaplanan Dice kaybı değeri.\n    \"\"\"\n    return -dice_coefficients(y_true, y_pred, smooth)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:13.087157Z","iopub.execute_input":"2024-08-20T07:20:13.087556Z","iopub.status.idle":"2024-08-20T07:20:13.104418Z","shell.execute_reply.started":"2024-08-20T07:20:13.087522Z","shell.execute_reply":"2024-08-20T07:20:13.103289Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Intersection over Union (IoU) Hesaplama Fonksiyonu","metadata":{}},{"cell_type":"markdown","source":"* IoU: Bu fonksiyon, tahmin edilen ve gerçek maskelerin ne kadar örtüştüğünü gösteren Intersection over Union (IoU) değerini hesaplar.","metadata":{}},{"cell_type":"code","source":"def iou(y_true, y_pred, smooth=100):\n    \"\"\"\n    Gerçek ve tahmin edilen değerler arasındaki Intersection over Union (IoU) değerini hesaplar.\n\n    IoU, segmentasyon problemlerinde tahmin edilen maskelerin gerçek maskelerle ne kadar örtüştüğünü ölçen bir metriktir.\n\n    Parametreler:\n    -----------\n    y_true : tensor\n        Gerçek değerler (genellikle bir ikili maske).\n\n    y_pred : tensor\n        Tahmin edilen değerler (genellikle bir ikili maske).\n\n    smooth : float, optional\n        Sıfır bölmeyi önlemek için kullanılan bir düzeltme faktörü. Varsayılan değer 100'dür.\n    \n    Döndürülen:\n    --------\n    float\n        Gerçek ve tahmin edilen değerler arasındaki IoU değeri.\n    \"\"\"\n    intersection = K.sum(y_true * y_pred)\n    sum = K.sum(y_true + y_pred)\n    iou = (intersection + smooth) / (sum - intersection + smooth)\n    return iou\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:13.105983Z","iopub.execute_input":"2024-08-20T07:20:13.106814Z","iopub.status.idle":"2024-08-20T07:20:13.115143Z","shell.execute_reply.started":"2024-08-20T07:20:13.106772Z","shell.execute_reply":"2024-08-20T07:20:13.11435Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  Jaccard Mesafesi Hesaplama Fonksiyonu","metadata":{}},{"cell_type":"markdown","source":"* Jaccard Mesafesi: Bu fonksiyon, tahmin edilen ve gerçek etiketler arasındaki Jaccard mesafesini hesaplar. Jaccard mesafesi, setler arasındaki benzerliği ölçen bir metriktir ve daha düşük bir değer, daha iyi bir performans gösterir.","metadata":{}},{"cell_type":"code","source":"def jaccard_distance(y_true, y_pred):\n    \"\"\"\n    Gerçek etiketlerle tahmin edilen etiketler arasındaki Jaccard mesafesini hesaplar.\n\n    Jaccard mesafesi, setler arasındaki benzerliği ölçen bir metriktir. \n    Tahmin edilen etiketler ve gerçek etiketler arasındaki Jaccard mesafesi ne kadar düşükse,\n    modelin performansı o kadar iyidir.\n\n    Parametreler:\n    -----------\n    y_true : np.array\n        Gerçek etiket (ikili maske) dizisi.\n\n    y_pred : np.array\n        Tahmin edilen etiket (ikili maske) dizisi.\n    \n    Döndürülen:\n    --------\n    float\n        Gerçek etiketlerle tahmin edilen etiketler arasındaki Jaccard mesafesi.\n    \"\"\"\n    y_true_flatten = K.flatten(y_true)\n    y_pred_flatten = K.flatten(y_pred)\n    return -iou(y_true_flatten, y_pred_flatten)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:13.118007Z","iopub.execute_input":"2024-08-20T07:20:13.118387Z","iopub.status.idle":"2024-08-20T07:20:13.133384Z","shell.execute_reply.started":"2024-08-20T07:20:13.118363Z","shell.execute_reply":"2024-08-20T07:20:13.132574Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_from_img_path(3, 3 , image_filenames_train, mask_files )","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:13.137554Z","iopub.execute_input":"2024-08-20T07:20:13.137933Z","iopub.status.idle":"2024-08-20T07:20:15.737699Z","shell.execute_reply.started":"2024-08-20T07:20:13.137905Z","shell.execute_reply":"2024-08-20T07:20:15.736153Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DataFrame Oluşturmak ve Veriyi Train, Accuracy ve Test Setlerine Ayırma","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(data={'image_filenames_train': image_filenames_train, 'mask': mask_files })\n\ndf_train, df_test = train_test_split(df, test_size=0.1)\n\n# Further split this val and train\ndf_train, df_val = train_test_split(df_train, test_size=0.2)\n\nprint(df_train.shape)\nprint(df_test.shape)\nprint(df_val.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:15.73958Z","iopub.execute_input":"2024-08-20T07:20:15.74001Z","iopub.status.idle":"2024-08-20T07:20:15.768956Z","shell.execute_reply.started":"2024-08-20T07:20:15.739975Z","shell.execute_reply":"2024-08-20T07:20:15.767769Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_generator(\n    data_frame,\n    batch_size,\n    augmentation_dict,\n    image_color_mode=\"rgb\",\n    mask_color_mode=\"grayscale\",\n    image_save_prefix=\"image\",\n    mask_save_prefix=\"mask\",\n    save_to_dir=None,\n    target_size=(256, 256),\n    seed=1,\n):\n    \"\"\"\n    Bu fonksiyon, görüntü ve maskeleri aynı anda üretebilen bir veri üreticisi (generator) oluşturur.\n    `image_datagen` ve `mask_datagen` için aynı seed kullanarak, görüntü ve maskenin aynı dönüşümleri\n    geçmesini sağlar. Eğer üretici sonuçlarını görselleştirmek isterseniz, `save_to_dir` parametresini\n    belirli bir dizinle ayarlayın.\n    \"\"\"\n    image_datagen = ImageDataGenerator(**augmentation_dict)\n    mask_datagen = ImageDataGenerator(**augmentation_dict)\n\n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col=\"image_filenames_train\",  # Görüntü dosyalarının isimlerini içeren sütun adı\n        class_mode=None,\n        color_mode=image_color_mode,  # Görüntülerin renk modu\n        target_size=target_size,  # Görüntülerin hedef boyutu\n        batch_size=batch_size,  # Her bir seferde kaç görüntü üretileceği\n        save_to_dir=save_to_dir,  # Görüntülerin kaydedileceği dizin\n        save_prefix=image_save_prefix,  # Görüntü dosya isimlerinin ön eki\n        seed=seed,  # Rastgelelik için seed değeri\n    )\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col=\"mask\",  # Maske dosyalarının isimlerini içeren sütun adı\n        class_mode=None,\n        color_mode=mask_color_mode,  # Maskelerin renk modu (genellikle gri tonlama)\n        target_size=target_size,  # Maskelerin hedef boyutu\n        batch_size=batch_size,  # Her bir seferde kaç maske üretileceği\n        save_to_dir=save_to_dir,  # Maskelerin kaydedileceği dizin\n        save_prefix=mask_save_prefix,  # Maske dosya isimlerinin ön eki\n        seed=seed,  # Rastgelelik için seed değeri\n    )\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    # Görüntü normalizasyonu ve teşhis sonrası nihai dönüş\n    for (img, mask) in train_gen:\n        img, mask = normalize_and_diagnose(img, mask)\n        yield (img, mask)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:15.770259Z","iopub.execute_input":"2024-08-20T07:20:15.770832Z","iopub.status.idle":"2024-08-20T07:20:15.785821Z","shell.execute_reply.started":"2024-08-20T07:20:15.770795Z","shell.execute_reply":"2024-08-20T07:20:15.785015Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# normalize_and_diagnose Fonksiyonu:\n\n* Görüntü ve maskeleri 0 ile 1 arasına normalize eder.\n* Maske değerlerini, 0.5'ten büyük olanları 1 ve 0.5 veya daha küçük olanları 0 olarak ayarlar. Bu, maskelerin belirli bir eşik değerine göre ikili hale gelmesini sağlar.\n*Maskenin 0.5'ten küçük değerleri, tümör içermediği düşünülen tamamen siyah bölgeler olarak kabul edilir.","metadata":{}},{"cell_type":"code","source":"def normalize_and_diagnose(img, mask):\n    \"\"\"\n    Görüntü ve maskeyi normalleştiren ve teşhis eden fonksiyon.\n    Maske normalizasyonundan sonra değer <= 0.5 olan maskeler tamamen siyah olarak kabul edilir\n    ve tümör içerdiği düşünülmez.\n    \"\"\"\n    img = img / 255  # Görüntüyü 0-1 aralığına normalize et\n    mask = mask / 255  # Maskeyi 0-1 aralığına normalize et\n    mask[mask > 0.5] = 1  # Maskedeki değerler 0.5'ten büyükse 1 olarak ayarla\n    mask[mask <= 0.5] = 0  # Maskedeki değerler 0.5 veya daha küçükse 0 olarak ayarla\n    return(img, mask)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:15.78723Z","iopub.execute_input":"2024-08-20T07:20:15.787832Z","iopub.status.idle":"2024-08-20T07:20:15.805039Z","shell.execute_reply.started":"2024-08-20T07:20:15.787793Z","shell.execute_reply":"2024-08-20T07:20:15.804144Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 25\nBATCH_SIZE = 32\nlearning_rate = 1e-3\nsmooth=100","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:15.806596Z","iopub.execute_input":"2024-08-20T07:20:15.807393Z","iopub.status.idle":"2024-08-20T07:20:15.816322Z","shell.execute_reply.started":"2024-08-20T07:20:15.807354Z","shell.execute_reply":"2024-08-20T07:20:15.815301Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# U-Net Modeli ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import (\n    Input,\n    Activation,\n    BatchNormalization,\n    Dropout,\n    Lambda,\n    Conv2D,\n    Conv2DTranspose,\n    MaxPooling2D,\n    concatenate,\n)\nfrom tensorflow.keras import backend as K\n\n\ndef unet(input_size=(256, 256, 3)):\n    \"\"\"\n    This function creates and returns a U-Net model. U-Net is a type of convolutional neural network\n    designed for fast and precise segmentation of images. It consists of a contracting (downsampling)\n    path and an expansive (upsampling) path, which gives it a U-shaped architecture.\n\n    Parameters:\n    -----------\n    input_size : tuple of int\n        The size of the input images. It is a 3-tuple for (height, width, channels).\n        Default is (256, 256, 3).\n\n    Returns:\n    --------\n    model : keras.models.Model\n        The constructed U-Net model.\n    \"\"\"\n    inputs = Input(input_size)\n\n    # First DownConvolution / Encoder Leg will begin, so start with Conv2D\n    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(inputs)\n    bn1 = Activation(\"relu\")(conv1)\n    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation(\"relu\")(bn1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(pool1)\n    bn2 = Activation(\"relu\")(conv2)\n    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation(\"relu\")(bn2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n\n    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(pool2)\n    bn3 = Activation(\"relu\")(conv3)\n    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation(\"relu\")(bn3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(pool3)\n    bn4 = Activation(\"relu\")(conv4)\n    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation(\"relu\")(bn4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\")(pool4)\n    bn5 = Activation(\"relu\")(conv5)\n    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\")(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation(\"relu\")(bn5)\n\n    \"\"\" Now UpConvolution / Decoder Leg will begin, so start with Conv2DTranspose\n    The gray arrows (in the above image) indicate the skip connections that concatenate the encoder feature map with the decoder, which helps the backward flow of gradients for improved training. \"\"\"\n    up6 = concatenate(\n        [\n            Conv2DTranspose(512, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(\n                bn5\n            ),\n            conv4,\n        ],\n        axis=3,\n    )\n    \"\"\" After every concatenation we again apply two consecutive regular convolutions so that the model can learn to assemble a more precise output \"\"\"\n    conv6 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(up6)\n    bn6 = Activation(\"relu\")(conv6)\n    conv6 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation(\"relu\")(bn6)\n\n    up7 = concatenate(\n        [\n            Conv2DTranspose(256, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(\n                bn6\n            ),\n            conv3,\n        ],\n        axis=3,\n    )\n    conv7 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(up7)\n    bn7 = Activation(\"relu\")(conv7)\n    conv7 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation(\"relu\")(bn7)\n\n    up8 = concatenate(\n        [\n            Conv2DTranspose(128, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(\n                bn7\n            ),\n            conv2,\n        ],\n        axis=3,\n    )\n    conv8 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(up8)\n    bn8 = Activation(\"relu\")(conv8)\n    conv8 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation(\"relu\")(bn8)\n\n    up9 = concatenate(\n        [\n            Conv2DTranspose(64, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(\n                bn8\n            ),\n            conv1,\n        ],\n        axis=3,\n    )\n    conv9 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(up9)\n    bn9 = Activation(\"relu\")(conv9)\n    conv9 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation(\"relu\")(bn9)\n\n    conv10 = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\")(bn9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:15.817988Z","iopub.execute_input":"2024-08-20T07:20:15.818758Z","iopub.status.idle":"2024-08-20T07:20:15.846169Z","shell.execute_reply.started":"2024-08-20T07:20:15.81872Z","shell.execute_reply":"2024-08-20T07:20:15.845375Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = unet()\nmodel.summary","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:15.847353Z","iopub.execute_input":"2024-08-20T07:20:15.847648Z","iopub.status.idle":"2024-08-20T07:20:17.269327Z","shell.execute_reply.started":"2024-08-20T07:20:15.847623Z","shell.execute_reply":"2024-08-20T07:20:17.268369Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\ndef scheduler(epoch, lr):\n    return lr * decay_rate\n\nlr_scheduler = LearningRateScheduler(scheduler)\n\n\ntrain_generator_param = dict(rotation_range=0.2,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\n\ntrain_gen = train_generator(df_train, BATCH_SIZE,\n                                train_generator_param,\n                                target_size=(im_height, im_width))\n    \ntest_gen = train_generator(df_val, BATCH_SIZE,\n                                dict(),\n                                target_size=(im_height, im_width))\n    \nmodel = unet(input_size=(im_height, im_width, 3))\n\n\n# decay kullanmadan learning_rate doğrudan belirleyin\n\nopt = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-7, amsgrad=False)\n\ndecay_rate = learning_rate / EPOCHS\n\nmodel.compile(optimizer=opt, loss=dice_coefficients_loss, metrics=[\"binary_accuracy\", iou, dice_coefficients])\n\ncallbacks = [ModelCheckpoint('unet.keras', verbose=1, save_best_only=True)]\n\n\n\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch=int(len(df_train) / BATCH_SIZE), \n                    epochs=EPOCHS, \n                    callbacks=callbacks,\n                    validation_data = test_gen,\n                    validation_steps=int(len(df_val) / BATCH_SIZE))","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:20:17.270812Z","iopub.execute_input":"2024-08-20T07:20:17.271263Z","iopub.status.idle":"2024-08-20T08:24:05.808451Z","shell.execute_reply.started":"2024-08-20T07:20:17.271224Z","shell.execute_reply":"2024-08-20T08:24:05.807335Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_post_training = history.history\n\ntrain_dice_coeff_list = history_post_training['dice_coefficients']\ntest_dice_coeff_list = history_post_training['val_dice_coefficients']\n\ntrain_jaccard_list = history_post_training['iou']\ntest_jaccard_list = history_post_training['val_iou']\n\ntrain_loss_list = history_post_training['loss']\ntest_loss_list = history_post_training['val_loss']\n\nplt.figure(1)\nplt.plot(test_loss_list, 'b-')\nplt.plot(train_loss_list, 'r-')\n\nplt.xlabel('iterations')\nplt.ylabel('loss')\nplt.title('loss graph', fontsize=12)\n\nplt.figure(2)\nplt.plot(train_dice_coeff_list, 'b-')\nplt.plot(test_dice_coeff_list, 'r-')\n\nplt.xlabel('iterations')\nplt.ylabel('accuracy')\nplt.title('Accuracy graph', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T08:25:45.167171Z","iopub.execute_input":"2024-08-20T08:25:45.16784Z","iopub.status.idle":"2024-08-20T08:25:45.793533Z","shell.execute_reply.started":"2024-08-20T08:25:45.167809Z","shell.execute_reply":"2024-08-20T08:25:45.792622Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(history.history.keys())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T08:25:24.034263Z","iopub.execute_input":"2024-08-20T08:25:24.03466Z","iopub.status.idle":"2024-08-20T08:25:24.039719Z","shell.execute_reply.started":"2024-08-20T08:25:24.034629Z","shell.execute_reply":"2024-08-20T08:25:24.038695Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nfor i in range(20):\n    index = np.random.randint(1, len(df_test.index))\n    img = cv2.imread(df_test['image_filenames_train'].iloc[index])\n    img = cv2.resize(img, (im_height, im_width))\n    img = img/255\n    # print(imgs.shape) (256, 256 , 3)\n    img = img[np.newaxis, :, :, : ]\n    # print(img.shape) # (1, 256, 256, 3)\n\n    predicted_img = model.predict(img)\n    \n    plt.figure(figsize=(12, 12))\n    plt.subplot(1, 3, 1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n\n    plt.subplot(1, 3, 2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask'].iloc[index])))\n    plt.title('Original Mask')\n\n    plt.subplot(1, 3, 3)\n    plt.imshow(np.squeeze(predicted_img) > 0.5 )\n    plt.title('Prediction')\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T08:25:56.621042Z","iopub.execute_input":"2024-08-20T08:25:56.621715Z","iopub.status.idle":"2024-08-20T08:26:21.182835Z","shell.execute_reply.started":"2024-08-20T08:25:56.621676Z","shell.execute_reply":"2024-08-20T08:26:21.181829Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Eğitim ve Doğrulama Kayıp Grafiği\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Eğitim Kaybı')\nplt.plot(history.history['val_loss'], label='Doğrulama Kaybı')\nplt.title('Eğitim ve Doğrulama Kaybı')\nplt.xlabel('Epoch')\nplt.ylabel('Kayıp')\nplt.legend()\n\n# Eğitim ve Doğrulama Doğruluk Grafiği\nplt.subplot(1, 2, 2)\nplt.plot(history.history['binary_accuracy'], label='Eğitim Doğruluğu')\nplt.plot(history.history['val_binary_accuracy'], label='Doğrulama Doğruluğu')\nplt.title('Eğitim ve Doğrulama Doğruluğu')\nplt.xlabel('Epoch')\nplt.ylabel('Doğruluk')\nplt.legend()\n\nplt.show()\n\n# Eğitim ve Doğrulama IoU Grafiği\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['iou'], label='Eğitim IoU')\nplt.plot(history.history['val_iou'], label='Doğrulama IoU')\nplt.title('Eğitim ve Doğrulama IoU')\nplt.xlabel('Epoch')\nplt.ylabel('IoU')\nplt.legend()\n\n# Eğitim ve Doğrulama Dice Coefficient Grafiği\nplt.subplot(1, 2, 2)\nplt.plot(history.history['dice_coefficients'], label='Eğitim Dice Coefficient')\nplt.plot(history.history['val_dice_coefficients'], label='Doğrulama Dice Coefficient')\nplt.title('Eğitim ve Doğrulama Dice Coefficient')\nplt.xlabel('Epoch')\nplt.ylabel('Dice Coefficient')\nplt.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T08:29:17.040903Z","iopub.execute_input":"2024-08-20T08:29:17.041826Z","iopub.status.idle":"2024-08-20T08:29:18.107871Z","shell.execute_reply.started":"2024-08-20T08:29:17.041786Z","shell.execute_reply":"2024-08-20T08:29:18.106815Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Kullanılan metrikleri listele\nprint(\"Kullanılan Metrikler: \", model.metrics_names)\n\n# Kullanılan kayıp fonksiyonu\nprint(\"Kayıp Fonksiyonu: \", model.loss)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T08:32:41.133258Z","iopub.execute_input":"2024-08-20T08:32:41.133655Z","iopub.status.idle":"2024-08-20T08:32:41.139674Z","shell.execute_reply.started":"2024-08-20T08:32:41.133622Z","shell.execute_reply":"2024-08-20T08:32:41.138637Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('/kaggle/working/model.h5')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T08:36:13.094785Z","iopub.execute_input":"2024-08-20T08:36:13.095584Z","iopub.status.idle":"2024-08-20T08:36:14.14365Z","shell.execute_reply.started":"2024-08-20T08:36:13.095545Z","shell.execute_reply":"2024-08-20T08:36:14.142456Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test veri seti üzerindeki performansı değerlendirin\nresults = model.evaluate(test_gen, steps=int(len(df_val) / BATCH_SIZE))\n\n# Döndürülen tüm değerleri yazdırın\nprint(f\"Test Results: {results}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T08:38:55.588771Z","iopub.execute_input":"2024-08-20T08:38:55.589522Z","iopub.status.idle":"2024-08-20T08:39:05.576239Z","shell.execute_reply.started":"2024-08-20T08:38:55.589488Z","shell.execute_reply":"2024-08-20T08:39:05.575099Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#faydalanılan kaynak:https://www.youtube.com/watch?v=X1q993i7Gic&list=PLxqBkZuBynVRAcsIU-aKf46keJvnV3z5n","metadata":{},"outputs":[],"execution_count":null}]}